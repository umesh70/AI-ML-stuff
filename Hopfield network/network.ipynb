{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- Have you ever considered using neural networks as a memory storage device?, it might seem a little unconventional, but in 1982, John Hopkins introduced Hopfield neural networks that could be used as a method for creating advanced computer memories.\n",
    "\n",
    "- These networks were first described as recurrent neural network and are based on spin glasses and Ising-Lenz-Little model.\n",
    "- In a series of papers between  2016 and 2020, large memory capacity models were developed based on hopfield networks and these models came to be known as modern hopfield networks.\n",
    "\n",
    "\n",
    "# Structure\n",
    "- A hopfield neural network is constructed using only a single layer of 'n' number of nuerons **(units)** which are binary in their nature, meaning the neuron can be active (1) or inactive (0).\n",
    " \n",
    "- Since the network are recurrent neural network, the output of the units are feeded back to the network as its input.\n",
    "- The connections betweeen the neurons are weighted, and are defined by a symmetric Weight Matrix **W**, where\n",
    "\n",
    "    **W(i,j) = W(j,i)**\n",
    "    - Meaning, the weight between the ith and the jth neuron is same as weight between the jth neuron and the ith neuron.\n",
    "\n",
    "    **W(i,i) = 0\n",
    "    - Meaning there is are no self connections, that is diagonal elements of the weight matrix W are 0.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
